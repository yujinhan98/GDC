Load Pretrained Model Falsebatch_size:32
epochs:50
lr:0.001
decay:0.0001
momomentum:0.9
disk_epochs:15
disk_lr:1e-05
use_label:True
adjust:False
eval_weight:10
hcs:None
upweight_factor:auto
save_path:./snapshots/
seed:0
gpu:7
model_type:r50
load:None
sload:None
dataset:celebA
es:eval
mode:downweight
lambdas:50
g1:None
g2:None
g3:None
g4:None
save:./snapshots/celebAr50_epoch50_lr0.001_eseval_downweight
epoch,train_loss,KL_loss,pre_error(%)
001,0.3168,0.0128,0.4443
002,0.3202,0.0107,0.4274
003,0.3343,0.0078,0.4123
004,0.3495,0.0050,0.3992
005,0.3545,0.0032,0.3869
006,0.3598,0.0017,0.3766
007,0.3624,0.0006,0.3685
008,0.3619,0.0000,0.3623
009,0.3566,0.0003,0.3595
010,0.3358,0.0025,0.3611
011,0.2829,0.0086,0.3691
012,0.1467,0.0243,0.3897
013,-0.2484,0.0673,0.4247
014,-1.7748,0.2254,0.4790
015,-12.1548,1.2675,0.5198
DISK: train_accuracy,eval_accuracy,test_accuracy
0.8057,0.7838,0.7884
DISK: train_saccuracy,eval_saccuracy,test_saccuracy
0.6683,0.7118,0.6533
Predicted Train Group Info:
Key (0, 1.0) has 25029 samples before balancing
Key (0, 0.0) has 113474 samples before balancing
Key (1, 0.0) has 6594 samples before balancing
Key (1, 1.0) has 17673 samples before balancing
Group Info:
Indices for key (0, 1.0): 6594
Key (0, 1.0) has 6594 samples after balancing
Indices for key (0, 0.0): 6594
Key (0, 0.0) has 6594 samples after balancing
Indices for key (1, 0.0): 6594
Key (1, 0.0) has 6594 samples after balancing
Indices for key (1, 1.0): 6594
Key (1, 1.0) has 6594 samples after balancing
Predicted Eval Group Info:
Eval Key (0, 0) has 8535 samples before balancing
Eval Key (0, 1) has 8276 samples before balancing
Eval Key (1, 0) has 2874 samples before balancing
Eval Key (1, 1) has 182 samples before balancing
The eval group with the minimum number of samples is (1, 1) with 182 samples.
epoch,train_loss,train ACC, min ACC, test ACC,test worst Acc
Saved best model with accuracy: 0.7692307692307693 at epoch 0
001,0.2799, 0.8848, 0.7692, 0.9386, 0.7167
Saved best model with accuracy: 0.7967032967032966 at epoch 1
002,0.2259, 0.8976, 0.7967, 0.9348, 0.7667
Saved best model with accuracy: 0.9120879120879121 at epoch 2
003,0.2059, 0.9050, 0.9121, 0.9103, 0.9167
004,0.1971, 0.9096, 0.8956, 0.9179, 0.8833
Saved best model with accuracy: 0.945054945054945 at epoch 4
005,0.1878, 0.9126, 0.9451, 0.9120, 0.9222
006,0.1833, 0.9151, 0.8736, 0.9263, 0.8222
007,0.1744, 0.9175, 0.9121, 0.9186, 0.8833
008,0.1658, 0.9197, 0.8516, 0.9306, 0.8222
009,0.1581, 0.9217, 0.8352, 0.9336, 0.7889
010,0.1502, 0.9235, 0.8132, 0.9371, 0.7722
011,0.1451, 0.9251, 0.9341, 0.8965, 0.9056
012,0.1351, 0.9269, 0.8077, 0.9204, 0.8222
013,0.1304, 0.9286, 0.9451, 0.8895, 0.9389
014,0.1231, 0.9301, 0.8407, 0.9293, 0.8278
015,0.1175, 0.9317, 0.8901, 0.8955, 0.9111
016,0.1145, 0.9330, 0.8736, 0.9144, 0.8667
017,0.1031, 0.9346, 0.8297, 0.9185, 0.8444
018,0.1035, 0.9359, 0.7527, 0.9388, 0.7222
019,0.0971, 0.9373, 0.8352, 0.9230, 0.7778
020,0.0881, 0.9387, 0.9066, 0.9044, 0.8833
021,0.0881, 0.9399, 0.8791, 0.9132, 0.8500
022,0.0837, 0.9412, 0.8626, 0.9211, 0.8611
023,0.0735, 0.9425, 0.8242, 0.9330, 0.7889
024,0.0706, 0.9438, 0.6813, 0.9420, 0.6333
025,0.0648, 0.9450, 0.8956, 0.9224, 0.8556
026,0.0680, 0.9461, 0.8407, 0.9216, 0.8111
027,0.0580, 0.9473, 0.8022, 0.9319, 0.7222
028,0.0632, 0.9484, 0.8077, 0.9036, 0.8611
029,0.0561, 0.9494, 0.8846, 0.9066, 0.8611
030,0.0508, 0.9504, 0.8626, 0.9054, 0.8889
031,0.0463, 0.9515, 0.8736, 0.9029, 0.8778
032,0.0482, 0.9523, 0.8022, 0.9351, 0.7278
033,0.0528, 0.9532, 0.8077, 0.9152, 0.8500
034,0.0436, 0.9541, 0.8681, 0.9175, 0.8833
035,0.0406, 0.9550, 0.8242, 0.9165, 0.8944
036,0.0412, 0.9558, 0.8297, 0.9219, 0.8389
037,0.0385, 0.9566, 0.7857, 0.9216, 0.7444
038,0.0357, 0.9574, 0.8242, 0.9229, 0.7889
039,0.0373, 0.9581, 0.8352, 0.9176, 0.8056
040,0.0377, 0.9588, 0.7473, 0.9358, 0.7222
041,0.0286, 0.9596, 0.8791, 0.9115, 0.8556
042,0.0283, 0.9603, 0.8462, 0.9160, 0.8167
043,0.0295, 0.9610, 0.8462, 0.9199, 0.8889
044,0.0300, 0.9616, 0.7857, 0.9178, 0.8222
045,0.0244, 0.9623, 0.8352, 0.9130, 0.8333
046,0.0276, 0.9628, 0.8187, 0.9267, 0.7778
047,0.0249, 0.9634, 0.8791, 0.9126, 0.8556
048,0.0244, 0.9640, 0.8187, 0.9242, 0.8111
049,0.0221, 0.9646, 0.9011, 0.8962, 0.8944
050,0.0201, 0.9652, 0.8901, 0.9011, 0.9000
Final Results: 
